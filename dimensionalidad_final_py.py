# -*- coding: utf-8 -*-
"""dimensionalidad_final.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H5SCXykJ6MhTwnqgWfH0fo0paQOxPKGB
"""

import cv2
import glob
import pandas as pd
import numpy as np
from scipy import stats
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import os

def extraer_caracteristicas(ruta_imagen):
    """
    Carga una imagen, la convierte a escala de grises y extrae
    estadísticas básicas (media, mediana, moda, max, min).
    """
    # Cargar imagen directamente
    img = cv2.imread(ruta_imagen)

    # Validación: verificar si la imagen se cargó correctamente
    if img is None:
        print(f"Advertencia: No se pudo cargar la imagen {ruta_imagen}")
        return None

    # Conversión directa BGR a Escala de Grises (ahorramos un paso)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Redimensionar (64x64)
    re_size = cv2.resize(gray, (64, 64))

    # Aplanar la imagen para cálculos estadísticos más rápidos
    flat_img = re_size.flatten()

    # Extracción de características
    media = np.mean(flat_img)
    mediana = np.median(flat_img)

    # stats.mode con axis=None busca la moda en todo el array
    mode_result = stats.mode(flat_img, axis=None, keepdims=True)
    moda = mode_result.mode[0] if isinstance(mode_result.mode, np.ndarray) else mode_result.mode

    maximo = np.max(flat_img)
    minimo = np.min(flat_img)

    return [media, mediana, moda, maximo, minimo]

def generar_dataset(rutas_dict, nombre_archivo="dataset.csv"):
    """
    Recorre los directorios, extrae características y guarda un CSV nuevo.
    """
    datos = []
    print("Procesando imágenes...")

    for clase, ruta_patron in rutas_dict.items():
        archivos = glob.glob(ruta_patron)
        print(f" -> Procesando clase '{clase}': {len(archivos)} imágenes encontradas.")

        for ruta in archivos:
            features = extraer_caracteristicas(ruta)
            if features:
                features.append(clase)
                datos.append(features)

    columnas = ["Media", "Mediana", "Moda", "Maximo", "Minimo", "Clase"]
    df = pd.DataFrame(datos, columns=columnas)

    df.to_csv(nombre_archivo, index=False, header=False)
    print(f"Dataset guardado exitosamente en '{nombre_archivo}' con {len(df)} registros.")

def entrenar_knn(ruta_dataset):
    if not os.path.exists(ruta_dataset):
        print("Error: El archivo del dataset no existe.")
        return

    # Cargar datos
    data = pd.read_csv(ruta_dataset, header=None)

    # Separar Features (X) y Etiquetas (y)
    X = data.iloc[:, :-1].values
    y = data.iloc[:, -1].values

    print(f"Dataset cargado: {X.shape[0]} instancias, {X.shape[1]} características.")

    # Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)

    # Modelo
    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(X_train, y_train)

    # Evaluación
    y_pred = knn.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    print("--- Resultados ---")
    print(f"Exactitud (Accuracy): {acc*100:.2f}%")

    return knn

def main():
    # Diccionario de rutas para mantener el código ordenado
    rutas = {
        'A': 'A/*.JPG',
        'B': 'B/*.JPG',
        'C': 'C/*.JPG',
        'D': 'D/*.JPG'
    }

    # 1. Generar el dataset:
    generar_dataset(rutas)

    # 2. Entrenar el modelo:
    entrenar_knn("dataset.csv")

if __name__ == '__main__':
    main()